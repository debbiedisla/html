<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Readings</title>
</head>
<body>

  <header>
    <h1>Readings</h1>
    <p><a href="index.html">← Back to Home</a></p>
    <hr>
  </header>

  <main>
    <article>
      <h2>With ‘AI slop’ distorting our reality, the world is sleepwalking into disaster</h2>
      <p><em>Date:</em> February 16, 2026</p>

      <p>
        In the article for Nesrine Malik expressed concern over what she described as an onslaught of AI slop dominating internet content. She defined AI slop as AI-generated imagery, video and text which is shallow, addictive and ludicrously cheap. Malik said this slop creates noise that is entertainment that aims to inflame people rather than inform them, which confuses our understanding of reality and what is fake.
      </p>
      <p>
      The core of Malik’s argument resonates deeply. AI slop isn’t simply “junk content”; its content engineered for the attention economy. Social media platforms reward engagement — clicks, likes, comments — and the easiest way to generate that engagement at scale is with repetitive, sensational, emotionally charged material, rather than thoughtful or accurate information. Troubling is that the AI generated pieces seem so real. If something looks legitimate, even savvy users may believe it's real if they don't look close enough.  
      </p>
      <p>
        One of the most compelling points in the article is how AI slop doesn’t just clutter our feeds; it shapes perception in a way that can shift political or cultural narratives. Malik describes examples where AI-generated political imagery and fabricated scenarios are circulated so widely that they reinforce certain ideologies or biases, intentionally or not. In such cases, AI becomes a tool not for augmenting understanding but for manufacturing convenient realities that align with someone’s preexisting views or agendas.
      </p>
      <p>
        I find this deeply concerning because it suggests that we are entering a new phase in the struggle over information integrity. In previous eras, misinformation was often limited by how quickly and cheaply it could be produced. AI removes those barriers. Now anyone can generate visually convincing material in seconds — and a fraction of it is indistinguishable from actual human-produced content. The content isn’t just low quality; it’s ubiquitous, adaptive and unaccountable in ways traditional misinformation never was.
      </p>
      <p> 
        Equally compelling, though, is Malik’s insistence that AI slop doesn’t just fool us. It also captures our attention and drains us of emotional reserves that would allow us to properly engage with the world around us — especially things that require more thought or nuance than AI slop does. When were aren’t being lied to, we’re being managed. Every emoji reaction, clickbait outrage link, and endless scroll renders us less able to care about, or even properly process in real-time, actual things that happen in the world, even when they’re terrible.
      </p>
      <p>
        There is such an incredible opportunity to use AI to help everyone be creators. To help make life better for all of us. But if we’re not careful, it will destroy the pillars our society has used to define truth. AI slop makes me think we should all be better consumers of online media. Demand better from platforms. Content quality is as important as content quantity. As a college student, this matters to me because so much of my learning depends on credible sources. If my feeds and search results are flooded with “AI slop,” it gets harder to tell what’s real, cite responsibly, and build original ideas instead of absorbing recycled misinformation.
      </p>
    </article>

    <hr>

    <section>
      <h2>More readings (coming soon)</h2>
      <p>This page will be updated with my writing going forward.</p>
    </section>
  </main>

</body>
</html>
